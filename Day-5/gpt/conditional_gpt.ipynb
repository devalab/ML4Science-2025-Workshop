{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d90095",
   "metadata": {},
   "source": [
    "# Conditional Generative Pretrained Transformer (GPT)\n",
    "\n",
    "This notebook demonstrates generation of molecules using a GPT model conditioned on $logP$ and SAS values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f65e54",
   "metadata": {},
   "source": [
    "## Setting up the notebook and importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ab273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import QED, Descriptors\n",
    "from rdkit.Chem import RDConfig\n",
    "from rdkit import RDLogger\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\n",
    "import sascorer\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.ERROR)\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58be95e",
   "metadata": {},
   "source": [
    "## Load dataset, tokenize SMILES and make PyTorch `Dataloaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ea0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class ZincDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        self.data = data\n",
    "        self.max_len = block_size\n",
    "        self.pattern = re.compile(r\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\")\n",
    "        \n",
    "        # Build vocabulary from all SMILES in dataset\n",
    "        all_tokens = set()\n",
    "        for smiles in data['smiles']:\n",
    "            tokens = self.pattern.findall(smiles)\n",
    "            all_tokens.update(tokens)\n",
    "        all_tokens.add('<')  # Padding token\n",
    "        self.vocab = sorted(list(all_tokens))\n",
    "        self.stoi = {ch:i for i,ch in enumerate(self.vocab)}\n",
    "        self.itos = {i:ch for i,ch in enumerate(self.vocab)}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        smiles = self.data.iloc[idx]['smiles'].strip()\n",
    "        logp = self.data.iloc[idx]['logP']\n",
    "        sas = self.data.iloc[idx]['SAS']\n",
    "        \n",
    "        # Tokenize SMILES\n",
    "        tokens = self.pattern.findall(smiles)\n",
    "        tokens += ['<'] * (self.max_len - len(tokens))\n",
    "        if len(tokens) > self.max_len:\n",
    "            tokens = tokens[:self.max_len]\n",
    "        \n",
    "        try:\n",
    "            dix = [self.stoi[s] for s in tokens]\n",
    "        except KeyError as e:\n",
    "            print(f\"Error tokenizing: {smiles}\")\n",
    "            print(f\"Problem token: {e}\")\n",
    "            raise\n",
    "        \n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        props = torch.tensor([logp, sas], dtype=torch.float)\n",
    "        \n",
    "        return x, y, props\n",
    "    \n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    pattern = re.compile(r\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\")\n",
    "    lens = [len(pattern.findall(s)) for s in data['smiles']]\n",
    "    max_len = max(lens)\n",
    "    return data, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a66815a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, max_len = load_data('../../datasets/zinc250k.csv')\n",
    "dataset = ZincDataset(data, block_size=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a33e55",
   "metadata": {},
   "source": [
    "## Defining Elements of the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e825dac",
   "metadata": {},
   "source": [
    "### Self-Attention and Transformer Blocks\n",
    "\n",
    "*Causal Self Attention* which is a form of Masked Self Attention is used where only the tokens from the past until the present are used to predict the next token. Each block is a unit of the Conditional GPT model which is repeated several times in the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e4c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        self.key = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.query = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.value = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.attn_drop = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_drop = nn.Dropout(config.resid_pdrop)\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.n_head = config.n_head\n",
    "        \n",
    "        # Causal mask with space for property embeddings\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size + 1, config.block_size + 1))\n",
    "                             .view(1, 1, config.block_size + 1, config.block_size + 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        \n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_drop(att)\n",
    "        y = att @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_drop(self.proj(y))\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            nn.Dropout(config.resid_pdrop),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802012e8",
   "metadata": {},
   "source": [
    "### Defining the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a46a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
    "        self.drop = nn.Dropout(config.embd_pdrop)\n",
    "        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.prop_nn = nn.Linear(2, config.n_embd)  # For logP and SAS\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        print(\"number of parameters:\", sum(p.numel() for p in self.parameters()))\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        return self.config.block_size\n",
    "    \n",
    "    def forward(self, idx, targets=None, prop=None):\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, \"Cannot forward, model block size is exhausted.\"\n",
    "        \n",
    "        token_embeddings = self.tok_emb(idx)\n",
    "        position_embeddings = self.pos_emb[:, :t, :]\n",
    "        x = self.drop(token_embeddings + position_embeddings)\n",
    "        \n",
    "        if prop is not None:\n",
    "            p = self.prop_nn(prop.unsqueeze(1))\n",
    "            x = torch.cat([p, x], 1)\n",
    "        \n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "        \n",
    "        if prop is not None:\n",
    "            logits = logits[:, 1:, :]\n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.view(-1))\n",
    "        \n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19edc7d",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67029429",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "def train(model, dataset, batch_size=128, epochs=10, lr=3e-4):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader))\n",
    "        for it, (x, y, props) in pbar:\n",
    "            x = x.to('cuda')\n",
    "            y = y.to('cuda')\n",
    "            props = props.to('cuda')\n",
    "            \n",
    "            logits, loss = model(x, y, props)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            pbar.set_description(f\"epoch {epoch+1} iter {it}: loss {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973d7bc",
   "metadata": {},
   "source": [
    "#### Defining the Config file for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91b735c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTConfig:\n",
    "    def __init__(self, vocab_size, block_size, **kwargs):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size\n",
    "        self.embd_pdrop = 0.1\n",
    "        self.resid_pdrop = 0.1\n",
    "        self.attn_pdrop = 0.1\n",
    "        self.n_layer = 8\n",
    "        self.n_head = 8\n",
    "        self.n_embd = 256\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8acf76bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 6370048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1948: loss 0.40142: 100%|██████████| 1949/1949 [02:20<00:00, 13.83it/s]\n",
      "epoch 2 iter 1948: loss 0.35702: 100%|██████████| 1949/1949 [02:23<00:00, 13.61it/s]\n",
      "epoch 3 iter 1948: loss 0.32963: 100%|██████████| 1949/1949 [02:25<00:00, 13.44it/s]\n",
      "epoch 4 iter 1948: loss 0.32130: 100%|██████████| 1949/1949 [02:22<00:00, 13.68it/s]\n",
      "epoch 5 iter 1948: loss 0.30470: 100%|██████████| 1949/1949 [02:23<00:00, 13.61it/s]\n",
      "epoch 6 iter 1948: loss 0.29944: 100%|██████████| 1949/1949 [02:22<00:00, 13.69it/s]\n",
      "epoch 7 iter 1948: loss 0.29656: 100%|██████████| 1949/1949 [02:20<00:00, 13.87it/s]\n",
      "epoch 8 iter 1948: loss 0.29060: 100%|██████████| 1949/1949 [02:22<00:00, 13.70it/s]\n",
      "epoch 9 iter 1948: loss 0.27436: 100%|██████████| 1949/1949 [02:22<00:00, 13.63it/s]\n",
      "epoch 10 iter 1948: loss 0.28203: 100%|██████████| 1949/1949 [02:20<00:00, 13.83it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = GPTConfig(dataset.vocab_size, max_len, num_props=2)\n",
    "model = GPT(config).to('cuda')\n",
    "\n",
    "train(model, dataset, batch_size=128, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4617015",
   "metadata": {},
   "source": [
    "## Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38c71a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c154f87",
   "metadata": {},
   "source": [
    "## Generating molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d504b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, x, steps, temperature=1.0, sample=True, top_k=None, prop=None):\n",
    "    block_size = model.get_block_size()\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for k in range(steps):\n",
    "            x_cond = x if x.size(1) <= block_size else x[:, -block_size:]\n",
    "            logits, _ = model(x_cond, prop=prop)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, ix = torch.topk(logits, top_k)\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            if sample:\n",
    "                ix = torch.multinomial(probs, num_samples=1)\n",
    "            else:\n",
    "                _, ix = torch.topk(probs, k=1, dim=-1)\n",
    "            x = torch.cat((x, ix), dim=1)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380079c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating 10 molecules with logP=-1.21, SAS=6.99\n",
      "\n",
      "Generating 10 molecules with logP=4.20, SAS=4.82\n",
      "\n",
      "Generating 10 molecules with logP=-4.52, SAS=2.09\n",
      "\n",
      "Generating 10 molecules with logP=-6.00, SAS=6.47\n",
      "\n",
      "Generating 10 molecules with logP=2.22, SAS=5.49\n",
      "\n",
      "Generating 10 molecules with logP=-6.56, SAS=7.10\n",
      "\n",
      "Generating 10 molecules with logP=5.72, SAS=2.44\n",
      "\n",
      "Generating 10 molecules with logP=-4.13, SAS=2.26\n",
      "\n",
      "Generating 10 molecules with logP=-2.27, SAS=4.36\n",
      "\n",
      "Generating 10 molecules with logP=-0.34, SAS=2.93\n",
      "\n",
      "Generating 10 molecules with logP=2.38, SAS=1.99\n",
      "\n",
      "Generating 10 molecules with logP=-2.46, SAS=3.39\n",
      "\n",
      "Generating 10 molecules with logP=0.02, SAS=5.97\n",
      "\n",
      "Generating 10 molecules with logP=-3.86, SAS=4.30\n",
      "\n",
      "Generating 10 molecules with logP=2.09, SAS=1.42\n",
      "\n",
      "Generating 10 molecules with logP=2.31, SAS=2.18\n",
      "\n",
      "Generating 10 molecules with logP=-5.89, SAS=6.97\n",
      "\n",
      "Generating 10 molecules with logP=7.73, SAS=6.11\n",
      "\n",
      "Generating 10 molecules with logP=-2.27, SAS=1.73\n",
      "\n",
      "Generating 10 molecules with logP=3.48, SAS=3.84\n",
      "\n",
      "Generating 10 molecules with logP=-5.03, SAS=4.18\n",
      "\n",
      "Generating 10 molecules with logP=-6.36, SAS=6.73\n",
      "\n",
      "Generating 10 molecules with logP=-2.96, SAS=5.21\n",
      "\n",
      "Generating 10 molecules with logP=-2.16, SAS=4.33\n",
      "\n",
      "Generating 10 molecules with logP=1.39, SAS=2.27\n",
      "\n",
      "Generating 10 molecules with logP=7.79, SAS=5.90\n",
      "\n",
      "Generating 10 molecules with logP=7.34, SAS=6.64\n",
      "\n",
      "Generating 10 molecules with logP=2.17, SAS=6.81\n",
      "\n",
      "Generating 10 molecules with logP=-5.54, SAS=2.34\n",
      "\n",
      "Generating 10 molecules with logP=-6.19, SAS=3.14\n",
      "\n",
      "Generating 10 molecules with logP=-1.00, SAS=2.80\n",
      "\n",
      "Generating 10 molecules with logP=5.66, SAS=3.33\n",
      "\n",
      "Generating 10 molecules with logP=-2.63, SAS=4.47\n",
      "\n",
      "Generating 10 molecules with logP=-4.74, SAS=6.07\n",
      "\n",
      "Generating 10 molecules with logP=-5.75, SAS=7.21\n",
      "\n",
      "Generating 10 molecules with logP=4.81, SAS=2.36\n",
      "\n",
      "Generating 10 molecules with logP=-6.79, SAS=6.15\n",
      "\n",
      "Generating 10 molecules with logP=3.82, SAS=5.62\n",
      "\n",
      "Generating 10 molecules with logP=4.79, SAS=1.59\n",
      "\n",
      "Generating 10 molecules with logP=-1.45, SAS=1.85\n",
      "\n",
      "Generating 10 molecules with logP=6.18, SAS=4.97\n",
      "\n",
      "Generating 10 molecules with logP=-1.87, SAS=1.52\n",
      "\n",
      "Generating 10 molecules with logP=-2.17, SAS=3.13\n",
      "\n",
      "Generating 10 molecules with logP=4.16, SAS=5.06\n",
      "\n",
      "Generating 10 molecules with logP=6.55, SAS=4.04\n",
      "\n",
      "Generating 10 molecules with logP=-5.07, SAS=5.52\n",
      "\n",
      "Generating 10 molecules with logP=4.63, SAS=4.59\n",
      "\n",
      "Generating 10 molecules with logP=4.79, SAS=4.17\n",
      "\n",
      "Generating 10 molecules with logP=1.03, SAS=3.76\n",
      "\n",
      "Generating 10 molecules with logP=-6.49, SAS=1.80\n",
      "\n",
      "Generating 10 molecules with logP=-6.40, SAS=5.05\n",
      "\n",
      "Generating 10 molecules with logP=-2.12, SAS=4.26\n",
      "\n",
      "Generating 10 molecules with logP=6.85, SAS=2.67\n",
      "\n",
      "Generating 10 molecules with logP=-0.67, SAS=5.78\n",
      "\n",
      "Generating 10 molecules with logP=-3.41, SAS=1.61\n",
      "\n",
      "Generating 10 molecules with logP=-2.49, SAS=2.13\n",
      "\n",
      "Generating 10 molecules with logP=7.19, SAS=6.11\n",
      "\n",
      "Generating 10 molecules with logP=2.71, SAS=6.50\n",
      "\n",
      "Generating 10 molecules with logP=5.28, SAS=2.28\n",
      "\n",
      "Generating 10 molecules with logP=6.63, SAS=4.45\n",
      "\n",
      "Generating 10 molecules with logP=5.34, SAS=6.65\n",
      "\n",
      "Generating 10 molecules with logP=-2.07, SAS=1.81\n",
      "\n",
      "Generating 10 molecules with logP=-3.43, SAS=3.76\n",
      "\n",
      "Generating 10 molecules with logP=5.50, SAS=6.43\n",
      "\n",
      "Generating 10 molecules with logP=-6.77, SAS=4.28\n",
      "\n",
      "Generating 10 molecules with logP=-0.56, SAS=2.50\n",
      "\n",
      "Generating 10 molecules with logP=-5.06, SAS=3.21\n",
      "\n",
      "Generating 10 molecules with logP=7.39, SAS=3.12\n",
      "\n",
      "Generating 10 molecules with logP=0.97, SAS=5.46\n",
      "\n",
      "Generating 10 molecules with logP=-1.38, SAS=7.12\n",
      "\n",
      "Generating 10 molecules with logP=7.68, SAS=2.68\n",
      "\n",
      "Generating 10 molecules with logP=0.65, SAS=2.99\n",
      "\n",
      "Generating 10 molecules with logP=-2.57, SAS=1.36\n",
      "\n",
      "Generating 10 molecules with logP=2.35, SAS=4.23\n",
      "\n",
      "Generating 10 molecules with logP=-6.10, SAS=2.85\n",
      "\n",
      "Generating 10 molecules with logP=6.86, SAS=2.61\n",
      "\n",
      "Generating 10 molecules with logP=-4.68, SAS=4.15\n",
      "\n",
      "Generating 10 molecules with logP=8.04, SAS=2.62\n",
      "\n",
      "Generating 10 molecules with logP=3.29, SAS=5.82\n",
      "\n",
      "Generating 10 molecules with logP=-3.28, SAS=5.62\n",
      "\n",
      "Generating 10 molecules with logP=-1.31, SAS=5.03\n",
      "\n",
      "Generating 10 molecules with logP=2.71, SAS=4.43\n",
      "\n",
      "Generating 10 molecules with logP=-5.51, SAS=6.28\n",
      "\n",
      "Generating 10 molecules with logP=-2.02, SAS=2.28\n",
      "\n",
      "Generating 10 molecules with logP=-6.26, SAS=4.77\n",
      "\n",
      "Generating 10 molecules with logP=3.37, SAS=1.23\n",
      "\n",
      "Generating 10 molecules with logP=0.87, SAS=2.53\n",
      "\n",
      "Generating 10 molecules with logP=2.88, SAS=2.21\n",
      "\n",
      "Generating 10 molecules with logP=3.58, SAS=3.51\n",
      "\n",
      "Generating 10 molecules with logP=7.29, SAS=1.98\n",
      "\n",
      "Generating 10 molecules with logP=-1.72, SAS=1.83\n",
      "\n",
      "Generating 10 molecules with logP=7.11, SAS=6.53\n",
      "\n",
      "Generating 10 molecules with logP=-2.97, SAS=5.20\n",
      "\n",
      "Generating 10 molecules with logP=5.49, SAS=4.55\n",
      "\n",
      "Generating 10 molecules with logP=1.14, SAS=2.62\n",
      "\n",
      "Generating 10 molecules with logP=-5.47, SAS=6.66\n",
      "\n",
      "Generating 10 molecules with logP=6.75, SAS=5.03\n",
      "\n",
      "Generating 10 molecules with logP=-1.75, SAS=3.28\n",
      "\n",
      "Generating 10 molecules with logP=4.11, SAS=6.66\n",
      "\n",
      "Generating 10 molecules with logP=6.54, SAS=5.93\n",
      "\n",
      "Generated 1000 molecules.\n"
     ]
    }
   ],
   "source": [
    "# defining property ranges\n",
    "logp_range = (data['logP'].min(), data['logP'].max())\n",
    "sas_range = (data['SAS'].min(), data['SAS'].max())\n",
    "\n",
    "#number of target conditions and number of generations per condition\n",
    "num_conditions = 100\n",
    "num_samples_per_condition = 10\n",
    "\n",
    "generated_smiles = []\n",
    "generated_targets = []\n",
    "\n",
    "for _ in range(num_conditions):\n",
    "    target_logp = np.random.uniform(*logp_range)\n",
    "    target_sas = np.random.uniform(*sas_range)\n",
    "    \n",
    "    print(f\"\\nGenerating {num_samples_per_condition} molecules with logP={target_logp:.2f}, SAS={target_sas:.2f}\")\n",
    "    \n",
    "    for _ in range(num_samples_per_condition):\n",
    "        # Use context token if needed\n",
    "        context = \"C\"  # or \"\" if not needed\n",
    "        x = torch.tensor([dataset.stoi[s] for s in dataset.pattern.findall(context)], dtype=torch.long)[None,...].to('cuda')\n",
    "        props = torch.tensor([target_logp, target_sas], dtype=torch.float)[None,...].to('cuda')\n",
    "        \n",
    "        y = sample(model, x, steps=100, temperature=1.0, prop=props)\n",
    "        completion = ''.join([dataset.itos[int(i)] for i in y[0]]).replace('<', '')\n",
    "        \n",
    "        generated_smiles.append(completion)\n",
    "        generated_targets.append((target_logp, target_sas))\n",
    "\n",
    "print(f\"\\nGenerated {len(generated_smiles)} molecules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbdf464",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbfc7f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1000/1000 [00:01<00:00, 704.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity: 78.70% (787 / 1000)\n",
      "Accuracy (Both in limit): 29.86% (235 / 787)\n",
      "Accuracy (logP in ±0.4): 33.29% (262 / 787)\n",
      "Accuracy (SAS in ±0.5): 74.21% (584 / 787)\n",
      "MAE logP: 1.0326\n",
      "MAE SAS: 0.3765\n",
      "Novelty: 100.00% (785 / 785)\n",
      "Uniqueness: 99.75% (785 / 787)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tr_data = set(data['smiles'])\n",
    "\n",
    "tol_logp = 0.4\n",
    "tol_sas = 0.5\n",
    "\n",
    "results = []\n",
    "\n",
    "# tracking accuracy\n",
    "both_in_limit = 0\n",
    "logp_in_limit = 0\n",
    "sas_in_limit = 0\n",
    "valid_count = 0\n",
    "\n",
    "logp_errors = []\n",
    "sas_errors = []\n",
    "\n",
    "# tracking novelty and uniqueness\n",
    "unique_smiles = set()\n",
    "unique_novel_smiles = set()\n",
    "\n",
    "generated_logps = []\n",
    "generated_sass = []\n",
    "\n",
    "for smiles, (target_logp, target_sas) in tqdm(zip(generated_smiles, generated_targets), \n",
    "                                              total=len(generated_smiles), desc=\"Evaluating\"):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        logp = Descriptors.MolLogP(mol)\n",
    "        qed = QED.qed(mol)\n",
    "        sa = sascorer.calculateScore(mol)\n",
    "\n",
    "        logp_error = abs(logp - target_logp)\n",
    "        sas_error = abs(sa - target_sas)\n",
    "\n",
    "        logp_ok = logp_error <= tol_logp\n",
    "        sas_ok = sas_error <= tol_sas\n",
    "        both_ok = logp_ok and sas_ok\n",
    "\n",
    "        # Update counters\n",
    "        if logp_ok:\n",
    "            logp_in_limit += 1\n",
    "        if sas_ok:\n",
    "            sas_in_limit += 1\n",
    "        if both_ok:\n",
    "            both_in_limit += 1\n",
    "\n",
    "        valid_count += 1\n",
    "        logp_errors.append(logp_error)\n",
    "        sas_errors.append(sas_error)\n",
    "\n",
    "        generated_logps.append(logp)\n",
    "        generated_sass.append(sa)\n",
    "\n",
    "        # Track uniqueness\n",
    "        unique_smiles.add(smiles)\n",
    "\n",
    "        # Track novelty correctly\n",
    "        if smiles not in tr_data:\n",
    "            unique_novel_smiles.add(smiles)\n",
    "\n",
    "        # Store result\n",
    "        results.append({\n",
    "            \"SMILES\": smiles,\n",
    "            \"Target_logP\": target_logp,\n",
    "            \"Target_SAS\": target_sas,\n",
    "            \"logP\": logp,\n",
    "            \"SAS\": sa,\n",
    "            \"QED\": qed,\n",
    "            \"logP_Error\": logp_error,\n",
    "            \"SAS_Error\": sas_error,\n",
    "            \"logP_in_limit\": logp_ok,\n",
    "            \"SAS_in_limit\": sas_ok,\n",
    "            \"Both_in_limit\": both_ok\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "# calculating metrics\n",
    "total_generated = len(generated_smiles)\n",
    "validity = valid_count / total_generated * 100 if total_generated else 0\n",
    "\n",
    "accuracy_both = both_in_limit / valid_count * 100 if valid_count else 0\n",
    "accuracy_logp = logp_in_limit / valid_count * 100 if valid_count else 0\n",
    "accuracy_sas = sas_in_limit / valid_count * 100 if valid_count else 0\n",
    "\n",
    "mae_logp = np.mean(logp_errors) if logp_errors else None\n",
    "mae_sas = np.mean(sas_errors) if sas_errors else None\n",
    "\n",
    "# Novelty\n",
    "novelty = len(unique_novel_smiles) / len(unique_smiles) * 100 if unique_smiles else 0\n",
    "\n",
    "# Uniqueness\n",
    "uniqueness = len(unique_smiles) / valid_count * 100 if valid_count else 0\n",
    "\n",
    "# metrics reporting\n",
    "print(f\"Validity: {validity:.2f}% ({valid_count} / {total_generated})\")\n",
    "print(f\"Accuracy (Both in limit): {accuracy_both:.2f}% ({both_in_limit} / {valid_count})\")\n",
    "print(f\"Accuracy (logP in ±{tol_logp}): {accuracy_logp:.2f}% ({logp_in_limit} / {valid_count})\")\n",
    "print(f\"Accuracy (SAS in ±{tol_sas}): {accuracy_sas:.2f}% ({sas_in_limit} / {valid_count})\")\n",
    "print(f\"MAE logP: {mae_logp:.4f}\")\n",
    "print(f\"MAE SAS: {mae_sas:.4f}\")\n",
    "print(f\"Novelty: {novelty:.2f}% ({len(unique_novel_smiles)} / {len(unique_smiles)})\")\n",
    "print(f\"Uniqueness: {uniqueness:.2f}% ({len(unique_smiles)} / {valid_count})\")\n",
    "\n",
    "# save the generated molecules\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"conditional_generation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e29db",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binding-pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
