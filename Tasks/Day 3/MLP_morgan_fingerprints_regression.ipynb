{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536e5326",
   "metadata": {},
   "source": [
    "### Task : Predicting Hydration Free Energy using Morgan Fingerprints\n",
    "\n",
    "**Goal:** Predict the experimental hydration free energy value for molecules.\n",
    "\n",
    "In this task, you will build a neural network to predict **hydration free energy** values for molecules - a measure of how favorably they dissolve in water (in kcal/mol). You'll use Morgan fingerprints as molecular representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94791621",
   "metadata": {},
   "source": [
    "## Setting up the notebook and importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dace3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Chemistry\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253a58a",
   "metadata": {},
   "source": [
    "## Loading and Analyzing FreeSolv Dataset\n",
    "\n",
    "The FreeSolv dataset contains experimental and calculated hydration free energy data for small molecules.\n",
    "We've already loaded it for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92aadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_freesolv_dataset():\n",
    "    \"\"\"Load the FreeSolv hydration free energy dataset\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/MobleyLab/FreeSolv/master/database.txt\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse the semicolon-delimited file\n",
    "    lines = response.text.strip().split('\\n')\n",
    "    \n",
    "    # Filter out comment lines\n",
    "    data_lines = [line for line in lines if not line.startswith('#') and line.strip()]\n",
    "    \n",
    "    # Parse each line\n",
    "    smiles_list = []\n",
    "    names_list = []\n",
    "    expt_values = []\n",
    "    calc_values = []\n",
    "    \n",
    "    for line in data_lines:\n",
    "        parts = [p.strip() for p in line.split(';')]\n",
    "        if len(parts) >= 6:  # Ensure we have enough fields\n",
    "            smiles = parts[1]  # SMILES string\n",
    "            name = parts[2]    # Molecule name\n",
    "            try:\n",
    "                exp_value = float(parts[3])   # Experimental hydration free energy\n",
    "                calc_value = float(parts[5])  # Calculated hydration free energy\n",
    "                # Validate SMILES before adding\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol is not None:\n",
    "                    smiles_list.append(smiles)\n",
    "                    names_list.append(name)\n",
    "                    expt_values.append(exp_value)\n",
    "                    calc_values.append(calc_value)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'SMILES': smiles_list,\n",
    "        'name': names_list,\n",
    "        'expt': expt_values,\n",
    "        'calc': calc_values\n",
    "    })\n",
    "\n",
    "    df = load_freesolv_dataset()\n",
    "\n",
    "    print(f\"Loaded FreeSolv with {len(df)} compounds\")# Load dataset\n",
    "\n",
    "    print(\"Columns in dataset:\", df.columns.tolist())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073f065",
   "metadata": {},
   "source": [
    "## Task 1: Data Visualization\n",
    "\n",
    "**TODO:** Plot the distribution of hydration free energies in the FreeSolv dataset.\n",
    "- Create a histogram showing the distribution of experimental hydration free energy values\n",
    "- Create a scatter plot showing the values across the dataset\n",
    "- Compare experimental vs. calculated values to see how well computational methods perform\n",
    "- Analyze the range and distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement visualization code here\n",
    "# Hint: Use plt.hist() and plt.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57264e5",
   "metadata": {},
   "source": [
    "## Task 2: Calculate Molecular Descriptors (Exploratory Analysis)\n",
    "\n",
    "**TODO:** Calculate LogP values for all molecules in the dataset.\n",
    "\n",
    "**Note:** LogP (partition coefficient) is NOT in the dataset - you'll calculate it using RDKit. This is for exploratory analysis to understand the relationship between lipophilicity (LogP) and hydration free energy.\n",
    "\n",
    "- Use RDKit's Descriptors.MolLogP() function to calculate LogP\n",
    "\n",
    "- Store the results in a new column 'LogP'- Explore the correlation between LogP and hydration free energy (the target we're predicting)\n",
    "- Plot the distribution of LogP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad385fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate LogP for each molecule\n",
    "# Hint: Loop through df['SMILES'], convert to mol objects, then calculate LogP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa614951",
   "metadata": {},
   "source": [
    "## Task 3: Set Hyperparameters and Generate Fingerprints\n",
    "\n",
    "**TODO:** Define hyperparameters and generate Morgan fingerprints for all molecules.\n",
    "\n",
    "Morgan fingerprints are computational tools that represent molecules as binary bit strings, encoding structural features by identifying circular substructures around each atom.\n",
    "\n",
    "Key hyperparameters:\n",
    "- `FINGERPRINT_SIZE`: Length of the fingerprint vector (try 128, 512, 1024, 2048)\n",
    "- `MAX_RADIUS`: Maximum radius for substructure consideration (try 2, 3, 4, 5)\n",
    "- `BATCH_SIZE`: Number of samples per training batch\n",
    "- `NUM_EPOCHS`: Number of training epochs\n",
    "- `LEARNING_RATE`: Learning rate for the optimizer\n",
    "- `DROPOUT`: Dropout rate for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122795dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define hyperparameters\n",
    "FINGERPRINT_SIZE = 2048\n",
    "MAX_RADIUS = 3\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 100\n",
    "WEIGHT_DECAY = 1e-3\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 3\n",
    "FACTOR = 0.5\n",
    "EARLY_STOPPING = 10\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc27cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate Morgan fingerprints\n",
    "# Hint: Use AllChem.GetMorganGenerator() and GetFingerprint()\n",
    "# Store fingerprints in df['morgan']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc201b",
   "metadata": {},
   "source": [
    "### How do the hyperparameters matter?\n",
    "\n",
    "- **FINGERPRINT_SIZE**: Larger sizes can encode more substructures with fewer collisions, but result in larger models that train slower\n",
    "- **MAX_RADIUS**: Controls how far to look around each atom for substructures\n",
    "\n",
    "**Challenge:** Experiment with different hyperparameter values to see how they affect model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6120554",
   "metadata": {},
   "source": [
    "## Task 4: Define PyTorch Dataset and DataLoaders\n",
    "\n",
    "**TODO:** Create a custom PyTorch Dataset class and instantiate train/test DataLoaders.\n",
    "- Implement the `__len__` and `__getitem__` methods\n",
    "- Split data into train/test sets (80/20 split)\n",
    "- Use 'expt' column as the target variable (experimental hydration free energy in kcal/mol)\n",
    "- Create DataLoader objects for both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee803a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define FPDataset class\n",
    "# TODO: Split data into train/test\n",
    "# TODO: Create DataLoader objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f8659",
   "metadata": {},
   "source": [
    "## Task 5: Define MLP Model Architecture\n",
    "\n",
    "**TODO:** Define a Multi-Layer Perceptron (MLP) for regression.\n",
    "- Input layer: size = FINGERPRINT_SIZE\n",
    "- Hidden layers: implement at least 2 hidden layers with ReLU activation\n",
    "- Dropout layers for regularization\n",
    "- Output layer: single neuron for regression (no activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1856cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define MLP class\n",
    "# TODO: Instantiate model, loss criterion (MSELoss), and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e2495",
   "metadata": {},
   "source": [
    "## Task 6: Train the Model\n",
    "\n",
    "**TODO:** Implement the training loop.\n",
    "- Training phase: forward pass, compute loss, backward pass, update weights\n",
    "- Validation phase: evaluate on test set without gradient updates\n",
    "- Implement learning rate scheduling\n",
    "- Implement early stopping based on validation loss\n",
    "- Track and store training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d7820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement train_model function\n",
    "# TODO: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee07e1",
   "metadata": {},
   "source": [
    "## Task 7: Evaluate Model Performance\n",
    "\n",
    "**TODO:** Visualize training progress and evaluate model performance.\n",
    "- Plot training and validation loss curves\n",
    "- Calculate regression metrics: MSE, MAE, RÂ² score\n",
    "- Create a scatter plot comparing predicted vs. actual values\n",
    "- Create a residual plot to analyze prediction errors\n",
    "- Compare your model's predictions with the calculated values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67622d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0fc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate predictions and regression metrics\n",
    "# TODO: Create prediction vs. actual scatter plot\n",
    "# TODO: Create residual plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
